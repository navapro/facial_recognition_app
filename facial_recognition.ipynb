{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlXL2yw482GA"
   },
   "source": [
    "Based on https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1037,
     "status": "ok",
     "timestamp": 1656015731002,
     "user": {
      "displayName": "N K",
      "userId": "15156018492042498558"
     },
     "user_tz": 300
    },
    "id": "ROxvO0_h5QRc",
    "outputId": "bec35f3c-e5c8-4c21-f2b9-0e8530b1d797"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2782,
     "status": "ok",
     "timestamp": 1656015733781,
     "user": {
      "displayName": "N K",
      "userId": "15156018492042498558"
     },
     "user_tz": 300
    },
    "id": "O5cKj3KR2_9d",
    "outputId": "3273b51f-e55a-479c-f30e-c6a5ed4b5da6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: tensorflow-gpu in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.47.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tensorflow-gpu opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ompGj5Bpwvo3"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MWI_5n09yWLO"
   },
   "outputs": [],
   "source": [
    "# Set GPU growth to avoid out of memory errors\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "executionInfo": {
     "elapsed": 195,
     "status": "error",
     "timestamp": 1656015733960,
     "user": {
      "displayName": "N K",
      "userId": "15156018492042498558"
     },
     "user_tz": 300
    },
    "id": "GBTJSFzG0UhU",
    "outputId": "eb186d49-934d-4bff-976f-7eed0e3df23a"
   },
   "outputs": [],
   "source": [
    "# Setting paths\n",
    "POS_PATH = os.path.join('data','positive')\n",
    "NEG_PATH = os.path.join('data','negative')\n",
    "ANC_PATH = os.path.join('data','anchor')\n",
    "\n",
    "# # Making the directories\n",
    "# os.makedirs(POS_PATH)\n",
    "# os.makedirs(NEG_PATH)\n",
    "# os.makedirs(ANC_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gl5ltu9B891i"
   },
   "source": [
    "Labeled data from http://vis-www.cs.umass.edu/lfw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_rGHwwDq9IaF"
   },
   "outputs": [],
   "source": [
    "# Uncompress the data and move it to negative folder\n",
    "# !tar -xf lfw.tgz\n",
    "# for directory in os.listdir('lfw'):\n",
    "#   for file_name in os.listdir(os.path.join('lfw', directory)):\n",
    "#     EX_PATH = os.path.join('lfw', directory, file_name)\n",
    "#     NEW_PATH = os.path.join(NEG_PATH, file_name)\n",
    "#     os.replace(EX_PATH, NEW_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 182,
     "status": "error",
     "timestamp": 1656017093237,
     "user": {
      "displayName": "N K",
      "userId": "15156018492042498558"
     },
     "user_tz": 300
    },
    "id": "W9dTOse321Zk",
    "outputId": "d8331b39-f720-4e65-efaa-ffce22b79122"
   },
   "outputs": [],
   "source": [
    "# Import uuid library to generate unique image names\n",
    "import uuid\n",
    "\n",
    "# Establish a connection to the webcam\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# while cap.isOpened(): \n",
    "#     ret, frame = cap.read()\n",
    "   \n",
    "#     # Cut down frame to 250x250px\n",
    "#     frame = frame[120:120+250,150:150+250, :]\n",
    "    \n",
    "#     # Collect anchors \n",
    "#     if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "#         # Create the unique file path \n",
    "#         imgname = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "#         # Write out anchor image\n",
    "#         cv2.imwrite(imgname, frame)\n",
    "    \n",
    "#     # Collect positives\n",
    "#     if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "#         # Create the unique file path \n",
    "#         imgname = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "#         # Write out positive image\n",
    "#         cv2.imwrite(imgname, frame)\n",
    "    \n",
    "#     # Show image back to screen\n",
    "#     cv2.imshow('Image Collection', frame)\n",
    "    \n",
    "#     # Breaking gracefully\n",
    "#     if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "#         break\n",
    "        \n",
    "# # Release the webcam\n",
    "# cap.release()\n",
    "# # Close the image show frame\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images\n",
    "\n",
    "anchor = tf.data.Dataset.list_files(ANC_PATH+ '\\*.jpg').take(300)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH+ '\\*.jpg').take(300)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH+ '\\*.jpg').take(300)\n",
    "\n",
    "def preprocess(file_path):\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    img = tf.image.resize(img, (105,105))\n",
    "    img = img/255.0\n",
    "    return img\n",
    "\n",
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)\n",
    "\n",
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return (preprocess(input_img), preprocess(validation_img), label)\n",
    "    \n",
    "# Data pipeline\n",
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size = 1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = round(len(data)* 0.7)\n",
    "train_data = data.take(sample_size)\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)\n",
    "\n",
    "test_data = data.skip(sample_size)\n",
    "test_data = test_data.take(round(len(data)*0.3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding():\n",
    "    def build_block(image, conv_size,dimention):\n",
    "        conv = Conv2D(dimention, (conv_size, conv_size),activation = 'relu')(image)\n",
    "        return MaxPooling2D(64,(2,2), padding = 'same')(conv)\n",
    "    \n",
    "    input_image = Input(shape = (105,105,3), name= 'input_img')\n",
    "    \n",
    "    block_1 = build_block(input_image, 10, 64)\n",
    "    block_2 = build_block(block_1, 7, 128)\n",
    "    block_3 = build_block(block_2, 4, 128)\n",
    "    \n",
    "    conv_layer = Conv2D(256, (4,4),activation = 'relu')(block_3)\n",
    "    flatten_layer = Flatten()(conv_layer)\n",
    "    dense_layer = Dense(4096, activation ='sigmoid')(flatten_layer)\n",
    "    \n",
    "    return Model(inputs = [input_image], outputs=[dense_layer], name='embedding')\n",
    "embedding = make_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building L1 Distance layer (https://stackoverflow.com/questions/59659494/euclidean-distance-in-keras)\n",
    "class L1Dist(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_siamese_model():\n",
    "    \n",
    "    input_image = Input(name = 'input_imgage', shape =(105,105,3))\n",
    "    validation_image = Input(name = 'validation_image', shape =(105,105,3))\n",
    "    \n",
    "    siamese_layer = L1Dist()\n",
    "    siamese_layer._name = 'distance'\n",
    "    distance_layer = siamese_layer(embedding(input_image), embedding(validation_image))\n",
    "    \n",
    "    classifier = Dense(1, activation = 'sigmoid')(distance_layer)\n",
    "    \n",
    "    return Model(inputs = [input_image, validation_image], outputs = classifier, name = 'SiameseNetwork')\n",
    "\n",
    "siamese_model = make_siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_imgage (InputLayer)      [(None, 105, 105, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " validation_image (InputLayer)  [(None, 105, 105, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)         (None, 4096)         38960448    ['input_imgage[0][0]',           \n",
      "                                                                  'validation_image[0][0]']       \n",
      "                                                                                                  \n",
      " distance (L1Dist)              (None, 4096)         0           ['embedding[6][0]',              \n",
      "                                                                  'embedding[7][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            4097        ['distance[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,964,545\n",
      "Trainable params: 38,964,545\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "\n",
    "binary_cross_loss = tf.losses.BinaryCrossentropy(from_logits = True)\n",
    "opt = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt = opt, siamese_model = siamese_model)\n",
    "\n",
    "# model.load(checkpoint_dir) # to get pretrained checkpoints instead of new train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        x = batch[:2]\n",
    "        y_true = batchf[2]\n",
    "        \n",
    "        y_pred = siamese_model(x, training = True)\n",
    "        loss = binary_cross_loss(y_true, y_pred)\n",
    "        print(loss)\n",
    "        \n",
    "        gradient = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "        opt.apply_gradient(zip(gradient, siamese_model.trainable_variables))\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "def train(data, EPOCHS):\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(train_data))\n",
    "        \n",
    "        for idx,batch in enumerate(train_data):\n",
    "            train_step(batch)\n",
    "            progbar.update(idx+1)\n",
    "            \n",
    "        if epoch % 10 ==0:\n",
    "            checkpoint.save(file_prefix= checkpoint_prefix)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPDZ3wlxVD8b8vTR90QKMfx",
   "collapsed_sections": [],
   "name": "facial_recognition.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "interpreter": {
   "hash": "550721ed2c2a6720aeec9a443e763565271123cb9de468022805afa2853380f5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
